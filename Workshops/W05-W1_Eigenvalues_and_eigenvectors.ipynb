{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "612ebd5a",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#  Week 5 worksheet 1: Calculating Eigenvalues and Eigenvectors\n",
    "\n",
    "This week, we investigate the use of EIGENVALUES AND EIGENVECTORS to find stability and it\n",
    "Ordinary Differential Equations (ODEs)\n",
    "\n",
    "The best way to learn programming is to write code. Don't hesitate to edit the code in the example cells, or add your own code, to test your understanding. You will find practice exercises throughout the notebook, denoted by ðŸš© ***Exercise $x$:***.\n",
    "\n",
    "#### Displaying solutions\n",
    "\n",
    "Solutions will be released one week after the worksheets are released, as a new `.txt` file in the same GitHub repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8625290c",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Fundamental equation:\n",
    "Equations of the type: <Br>\n",
    "***\n",
    "\\begin{equation}\n",
    "\\bf{A}  \\cdot \\bf{x} = \\lambda  \\cdot \\bf{x}\n",
    "\\label{eigen}\\tag{1}\n",
    "\\end{equation}\n",
    "***\n",
    "\n",
    "often ocurring in practice and must hold true for Eigenvectors and Egenvalues given a <span style=\"color:blue\">**square**</span> matrix $\\bf{A}$. <Br>\n",
    "where:\n",
    "- $\\bf{x}$ is the eigenvector ( remember: <span style=\"color:blue\">*non-zero vectors!*</span>) \n",
    "- $\\lambda$ is the eigenvalue of  $\\bf{A}$\n",
    "\n",
    "### Calculating eigenvalues and eigenvectors:\n",
    "Lets first re-write vector $\\bf{x}$ as: <Br>\n",
    "<Br>\n",
    "$\\bf{x}$ = $\\mathbf I_n$ $\\bf{x}$; $ $ where $\\mathbf I_n$ is identity matrix .<Br>\n",
    "Now,  if we substract, $\\lambda  \\cdot \\bf{x}$,  from both sides of Eq. \\ref{eigen}, we get:<Br>\n",
    "<Br>\n",
    "$ \\bf{A} \\bf{x} - \\lambda \\mathbf I_n \\bf{x} $ = 0\n",
    "<Br>\n",
    "And applying the ditributive property in matrix vector products:\n",
    "<Br>\n",
    "\\begin{equation}\n",
    "\\det \\left( \\bf{A}  - \\lambda \\mathbf I_n  \\right)\\bf{x} = 0\n",
    "\\label{det}\\tag{2}\n",
    "\\end{equation}\n",
    "<Br>\n",
    "The meaning of Eq. \\ref{det} is that if the matrix $\\bf{A}  - \\lambda \\mathbf I_n $ has a determinant 0, then\n",
    "those $\\lambda$ are going to satisfy a non-zero $\\bf{x}$.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e78def5",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Linear Algebra Review : <span style= \"color:blue\">**The Determinant**</span>\n",
    "The determinant is a property of any square matrix that describes the degree of coupling between equations.\n",
    "A standard method for symbolically computing the determinant of an n x n matrix involves cofactors and\n",
    "expanding by a row or by a column. Here, we describe the standard formulas for computing the\n",
    "determinants of 2x2 and 3x3 matrices using the Laplace Expansion method. For instance:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e0ca51",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Consider : \n",
    "$ \\bf{A} $ =\n",
    "$\\begin{pmatrix} \n",
    "\ta & b & c\\\\\n",
    "\td & e & f\\\\\n",
    "\tg & h & i \\\\\n",
    "\t\\end{pmatrix}$ \n",
    "<Br>\n",
    "<Br>\n",
    "For a 3x3 matrix the determinant is:\n",
    "<Br>\n",
    "<Br>\n",
    "$\\det( \\bf{A} ) = a \\begin{vmatrix} e & f\\\\h & i \\\\ \\end{vmatrix} -  b \\begin{vmatrix} d & f\\\\g & i \\\\ \\end{vmatrix} +  c \\begin{vmatrix} d & e\\\\g & h \\\\ \\end{vmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bf7532",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='figures/determinant3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f4c151",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Larger matrices are computed in the same way where the element of the top row is multiplied by the determinant of matrix remaining once that elementâ€™s row and column are removed. Terms where the top elements in odd columns are added and terms where the top elements in even rows are subtracted (assuming the top element is positive)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c37d59",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "ðŸš© ***Exercise 1:***  For a given <span style=\"color:blue\">**2x2**</span> matrix **A** the determinat can be calculated as follows: <Br>\n",
    "<Br>\n",
    "$\\det( \\bf{A} ) = \\begin{vmatrix} a & b\\\\c & d \\\\ \\end{vmatrix} = \\it{ad} - \\it{bc}$\n",
    "<Br>\n",
    "Create a *function* that calculates the determinant of any 2x2 input matrix \n",
    "<Br>\n",
    "___Hint___: notice that the calculation of the determinant  of a 2x2 matrix, $\\bf{A}$,  always involves the first element $\\bf{A}[0,0]$ andthe last  element $\\bf{A}[-1,-1]$ i.e., $\\bf{A}[n,n]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7606fa",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0810fe0",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run scripts/show_solutions.py W05-W1_ex1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8f387a",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "ðŸš© ***Exercise 2:***  \n",
    "Create a *function* that calculates the determinant of a any <span style=\"color:blue\">**3x3**</span> input matrix using the *Laplace Expansion method*, as described above.\n",
    "***\n",
    "___Hint 1___ : the larger square matrices are considered to \n",
    " be a combination of 2x2 matrices.\n",
    "***\n",
    "___Hint 2___ :In Python, you can construct matrices from elements of other matrices using librariy NumPy, which provides efficient operations for matrix manipulations. for instance, you can create a matrix by extracting elements or slices from other matrices and then combine them using *functions* like <span style=\"color:blue\">**np.hstack()**</span>.\n",
    "***\n",
    "__Notice__:It's important that you attempt to figure out how to solve this problem using code. This will allow you to put into practice many of the topics covered so far in the NMfCE course.\n",
    " <Br>\n",
    "Once you have tried, compare your results using  the availble <span style=\"color:blue\">**numpy.linalg.det()**</span> *function* which calculates the determinant of any input matrix.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0934e5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdb51eb-8e2f-4edc-978b-125c4c76f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/show_solutions.py W05-W1_ex2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eb5fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.array([[6,1,1], [4, -2, 5], [2,8,7]]) \n",
    "print(\"Determinant of matrix A using developed code:\", Det_matrix(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d612b1",
   "metadata": {},
   "source": [
    "Let's compare the results using  *numpy.linalg.det() function* to calculates the determinant of the input matrix A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf8ffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "detA = np.linalg.det(A)\n",
    "print(\"Determinant of matrix A using NumPy:\", detA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5344cc61",
   "metadata": {},
   "source": [
    "***\n",
    "**Important:** For larger matrices (4x4 and larger), solving for the eigenvalues and eigenvectors becomes very lengthy. Therefore  <span style=\"color:blue\">**numpy.linalg.det()**</span> will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d0a25",
   "metadata": {},
   "source": [
    "## Solving for eigenvalues and eigenvectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49faa8b",
   "metadata": {},
   "source": [
    "As can be seen from eq. ([2](#mjx-eqn-det)) , the eigenvalues are calculated first by setting $\\det \\left( \\bf{A}  - \\lambda \\mathbf I_n  \\right)$ to zero and then solving for $\\lambda$. The determinant is set to **zero** in order to ensure *non-trivial solutions* for $\\bf{x}$, by a fundamental theorem of linear algebra. For instance, \n",
    "let **A** be the next square matrix:\n",
    "<Br>\n",
    "<Br>    \n",
    "$ \\bf{A} $ =\n",
    "$\\begin{pmatrix} \n",
    "\t16 & -24 & 18\\\\\n",
    "\t 3 &  -2 &  0\\\\\n",
    "\t-9 &  18 &-17 \\\\\n",
    "\t\\end{pmatrix}$ \n",
    "<Br> \n",
    " Then:\n",
    "<Br>\n",
    " $ \\bf{A} - \\lambda \\mathbf I_n$ =\n",
    "$\\begin{pmatrix} \n",
    "\t16 & -24 & 18\\\\\n",
    "\t 3 &  -2 &  0\\\\\n",
    "\t-9 &  18 &-17 \\\\\n",
    "\t\\end{pmatrix}\n",
    "    +\n",
    "\\begin{pmatrix} \n",
    "\t-\\lambda & 0 & 0\\\\\n",
    "\t 0 &  -\\lambda &  0\\\\\n",
    "\t 0 &  0  & -\\lambda \\\\\n",
    "\t\\end{pmatrix}\n",
    "    $\n",
    "<Br> \n",
    "<Br>\n",
    " according to  eq. ([2](#mjx-eqn-det)), the determinant is set to Zero, therefore:\n",
    "***\n",
    "$\\det( \\bf{A} - \\lambda \\mathbf I_n) =  \\begin{vmatrix} 16-\\lambda & -24 & 18 \\\\3 & -2-\\lambda & 0 \\\\ -9 & 18 & -17-\\lambda\\end{vmatrix}  = 0$\n",
    "<Br> \n",
    "<Br>\n",
    "Expanding the determinat gives (Please, review it and verify): \n",
    "<Br> \n",
    "<Br>\n",
    "\\begin{equation}\n",
    "\\lambda^{3} + 3 \\lambda^{2} - 36 \\lambda + 32 = 0\n",
    "\\label{polyc} \\tag{3}\n",
    "\\end{equation}\n",
    "<Br> \n",
    "Equation \\ref{polyc} is the <span style=\"color:blue\">**characteristic polynomial**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b5275f",
   "metadata": {},
   "source": [
    "### Solving a characteristic polynomial using Python:\n",
    "Let's implement NumPy to find all the solutions of a characteristic polynomial function, it is to say all the roots satysfying \n",
    "([3](#mjx-eqn-polyc)). By using the *function* <span style=\"color:blue\">**roots(poly)**</span>, we obtain the roots of a polynomial  of power $N$ and variable $X$ with the corresponding coefficients given in <span style=\"color:blue\">\"poly\"</span>. In this fashion, the values in the rank-1 array <span style=\"color:blue\">\"poly\"</span> are coefficients of a polynomial. If the length of *poly* is *N*+1 then the polynomial is described by:\n",
    "***\n",
    "$ poly[0]*X^{n} +  poly[1]*X^{N-1} + ....+  poly[N-1]*X +  poly[N] $\n",
    "<Br>\n",
    "<Br>\n",
    "see the next code to find the roots of the polynomial $p(x) =  x^3 - 6x^2 + 11x - 6$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc4c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = [1, -6, 11, -6]\n",
    "roots_p = np.roots(poly)\n",
    "print(\"Roots of p(x):\", \"x1=\",roots_p[0],\"x2=\",roots_p[1],\"x3=\",roots_p[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1e84eb",
   "metadata": {},
   "source": [
    "In this way, Let's solve the characteristic polynomial ([3](#mjx-eqn-polyc)), or in other words let's calculate the eigenvalues of $\\bf{A}$, thus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e6aa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we define the array containig the coefficients of the characteristic polynomial (eq.3)\n",
    "coeff_lambda  = [1, 3,-36, 32]\n",
    "#---------------------------------------------------------------------------------------------\n",
    "# call function \"roots\" :\n",
    "eigen_values = np.roots(coeff_lambda)\n",
    "#----------------------------------------------------------------------------------------------\n",
    "print(\"Eigenvalues:\", \"\\u03BB1 = \", round(eigen_values[0]),\";\", \"\\u03BB2 = \", round(eigen_values[1]), \";\", \"\\u03BB3 = \", round(eigen_values[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c0e1a3",
   "metadata": {},
   "source": [
    "So, the <span style=\"color:blue\">**eigenvalues**</span> of our matrix $\\bf{A}$ are 4, 1, and -8.\n",
    "***\n",
    "### Eigenvectors: <Br>\n",
    "Having found the eigenvalues, for **each** value of $\\lambda$ an <span style=\"color:blue\">eigenvector</span> ,$\\bf{x}$,is calculated \n",
    "which will satisfy the equation ([2](#mjx-eqn-det)). For example, for the case of $\\lambda_3=1$ susbtitued in the corresponding equation we get (Notice that here, $\\bf{x} = \\rm[\\it{x_1,x_2,x_3}\\rm]$): \n",
    " <Br>    \n",
    "$\\begin{pmatrix} \n",
    "\t15 & -24 & 18\\\\\n",
    "\t 3 &  -3 &  0\\\\\n",
    "\t-9 &  18 &-18 \\\\\n",
    "\t\\end{pmatrix}\n",
    "\\begin{pmatrix} \n",
    "\tx_1 \\\\\n",
    "\tx_2 \\\\\n",
    "\tx_3 \\\\\n",
    "\t\\end{pmatrix}\n",
    "    = 0\n",
    "    $\n",
    "<Br>\n",
    "<Br>   \n",
    "Carrying out the **first stage** of a Gaussian elimination gives:\n",
    "<Br> \n",
    "$\\begin{pmatrix} \n",
    "\t15 & -24 & 18\\\\\n",
    "\t 0.0 &  1.8 & -3.6\\\\\n",
    "\t 0.0 &  3.6 & -7.2 \\\\\n",
    "\t\\end{pmatrix}\n",
    "\\begin{pmatrix} \n",
    "\tx_1 \\\\\n",
    "\tx_2 \\\\\n",
    "\tx_3 \\\\\n",
    "\t\\end{pmatrix}\n",
    "    = 0\n",
    "    $\n",
    "***\n",
    "As we knew from the lecture (W5) this week, the system of equations exhibits linear dependence and here we have fewer equations than unkwons, it is to say, there is **one degree of freedom** in this system of equations. However from the second and third equation the ratio of $x_2$ to $x_3$ is 2:1 and by substitution in the first equation the ratio of $x_1$ to $x_2$ is 1:1, therefore any vector with the ratios  $x_1$ :$x_2$ : $x_3$ = 1:2:2 is an **eigenvector** associated with the **eigenvalue** $\\lambda=1$. By convention we choose **x$_1$ = 1** , then:\n",
    "<Br>\n",
    "x$_1$ = 1\n",
    "<Br>   \n",
    "x$_2$ = 1 \n",
    "<Br>   \n",
    "x$_3$ = $\\frac{1}{2}$ \n",
    "<Br>\n",
    "getting an eigenvector that is:\n",
    "<Br>\n",
    "$ \\bf{x} =\\begin{pmatrix} \n",
    "\t1 \\\\\n",
    "\t1 \\\\\n",
    "\t\\frac{1}{2} \\\\\n",
    "\t\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0015e4eb",
   "metadata": {},
   "source": [
    "ðŸš© ***Exercise 3:***  <span style=\"color:red\">**Eigenvalues and Eigenvectors using Python**</span> \n",
    "<Br>\n",
    "Consider the square matrix $\\bf{M}$:\n",
    "<Br>\n",
    "<br>\n",
    "$ M=\\begin{pmatrix} \n",
    "\t4 & 1 & 4\\\\\n",
    "\t1 & 7 & 1\\\\\n",
    "\t4 & 1 & 4 \\\\\n",
    "\t\\end{pmatrix}$\n",
    "<Br>\n",
    "<br>\n",
    "Determine its eigenvalues and corresponding eigenvectors implementing: \n",
    "<Br>\n",
    "- the NumPy function **roots()** and your previous developed code for Gaussian elimination\n",
    "- the symbolic method using the SymPy Python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f19e050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84495ad5-d73b-4162-b45c-b308999252d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/show_solutions.py W05-W1_ex3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb51d0e",
   "metadata": {},
   "source": [
    "#### Notice:  \n",
    "The output of sp.roots is a dictionary of {*Key:Value*} pairs: *Keys* are the roots of the polynomial (eigenvalues) and *Values* are the multiplicities (how many times that root appears in the factorization of the polynomial). So, here\n",
    "The dictionary \"Eigs\" {9: 1, 6: 1, 0: 1} means:\n",
    "<Br>\n",
    " - 9 is a root (eigenvalue) of the characteristic polynomial with multiplicity 1 ( appears once in the factorization).\n",
    " - 6 is a root (eigenvalue) of the characteristic polynomial with multiplicity 1 \n",
    " - 0 is a root (eigenvalue) of the characteristic polynomial with multiplicity 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c16578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we don't care about multiplicities, then:\n",
    "lambdas =list(Eigs.keys())\n",
    "# this extract only the keys (eigenvalues) from the dictionary Eigs\n",
    "print(\"\\u03BB =\", lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76090e1",
   "metadata": {},
   "source": [
    "The set of <span style=\"color:blue\">*eigenvectors*</span> associated to corresponding eigenvalues $\\bf{\\lambda}$  can be found using the *sympy.Matrix().eigenvects()* method, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9feb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "M = Matrix(M)\n",
    "H = M.eigenvects()\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d45252",
   "metadata": {},
   "source": [
    "As can be seen here, the output of *eigenvects()* is a list where each entry is a tuple containing:<Br>\n",
    "- The eigenvalue.\n",
    "- The algebraic multiplicity of the eigenvalue.\n",
    "- A list of eigenvectors corresponding to that eigenvalue.\n",
    "****\n",
    "If you want the eigenvectors presented as plain and ordered lists of coordinates, then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f48af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "[list(evec[2][0]) for evec in M.eigenvects()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655ea28e",
   "metadata": {},
   "source": [
    "### Vector iteration : <span style=\"color:blue\">*Power Method*</span>. <Br>\n",
    "\n",
    "From the class material covered in Week 5, it is known that because of the presence of the unkwon vector $\\bf{x}$ on **both** sides of equation ([1](#mjx-eqn-eigen)), **iterative procedures** can be used to find an eigenvalue  $\\lambda_i$ , and correxpondinvector $\\bf{x_i}$  of the matrix it operates on. The main goal of the ___power method___ is to find the eigenvalue of largest (or smallest) absolute value of a matrix $\\bf{A}$, following the next iterative approach (see example in W05-L1):\n",
    "    \n",
    "- Step 0: Guess an initial solution, $\\bf{x^{(o)}}$, $\\lambda^{(\\text{o})}_{\\text{max}}$\n",
    "***\n",
    "- Step 1: Develop a *Matrix-by-vector* multiplication of the lef-hand side of Eq.([1](#mjx-eqn-eigen)) and obtain a resulting vector $\\bf{v}$\n",
    "***\n",
    "\\begin{equation}\n",
    "\\bf{A}  \\cdot \\bf{x^{(o)}} = \\bf{v}\n",
    "\\label{Pwstep1} \n",
    "\\end{equation}\n",
    "- Step 2: \"Normalize\" the resulting vector  by dividing by the largest absolute term in  $\\bf{v}$,  $ \\lvert \\it{v}_{i,\\text{max}} \\rvert$, :\n",
    "***\n",
    "\\begin{equation}\n",
    "    \\bf{\\hat{v}} = \\frac{\\bf{v}}{\\rm\\lvert \\it{v}_i \\rvert_{max}}\n",
    "\\end{equation}\n",
    "- Step 3: Make  $\\bf{x^{(o)}} = \\bf{\\hat{v}} $ and  $\\lambda^{(\\text{k})}_{\\text{max}}= \\it{v}_{i,\\text{max}}$ <Br>\n",
    "<Br>\n",
    "$\\;\\;\\;\\;\\;\\;$ IF: $   \\lVert \\lambda^{(\\text{k})}_{\\text{max}} -  \\lambda^{(\\text{o})}_{\\text{max}}\\rVert \\approx 0 $, THEN the procedure has finished and $\\lambda^{(\\text{k})}_{\\text{max}}$ is the largest eigenvalue and $\\bf{\\hat{v}}$ the corresponding eigenvector\n",
    "<Br>\n",
    "<Br>   \n",
    "$\\;\\;\\;\\;\\;\\;$ OTHERWISE: <Br>\n",
    "$\\;\\;\\;\\;\\;\\;$ $\\;\\;\\;\\;\\;\\;$   IF $ \\lvert \\lambda^{(\\text{k})}_{\\text{max}} \\rvert >  \\lvert \\lambda^{(\\text{o})}_{\\text{max}} \\rvert$ MAKE  $ \\lambda^{(\\text{o})}_{\\text{max}} = \\lambda^{(\\text{k})}_{\\text{max}} $\n",
    "<Br>\n",
    "$\\;\\;\\;\\;\\;\\;$  <span style=\"color:blue\">Go back to Step 1</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0ec9dc",
   "metadata": {},
   "source": [
    " ðŸš© ***Exercise 4:***  \n",
    "\n",
    "Consider the example presented in Week 5, class material (W05-L1), for the Power Method:\n",
    "\n",
    "$\\begin{pmatrix} \n",
    "\t3.556 & -1.778 & 0\\\\\n",
    "\t-1.778 & 3.556 & -1.778\\\\\n",
    "\t 0  &  1.778 & 3.556 \\\\\n",
    "\t\\end{pmatrix}$ $\\cdot \\bf{x} = \\bf{\\lambda}  \\cdot \\bf{x}$\n",
    "<Br>\n",
    "<Br>\n",
    "- Develop an iterative procedure in Pyhton to demonstrate that the power method converges towards the eigenvalue $\\lambda \\approx 6.0$, which is the eigenvalue with the largest absolute value.\n",
    "- Verify the reliability of your algorithm using the *SymPy* library. Are the results the same? Compare the eigenvectors obtained. What can you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa02fa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.array([[3.556,-1.778, 0],[-1.778,3.556,-1.778],[0,-1.778,3.556]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583e2390-73f8-42d3-bb6f-95ab20fe1004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e772b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/show_solutions.py W05-W1_ex4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ef31e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's verify the results obtained above using SymPy Library:\n",
    "# -------------------------------------------------------------\n",
    "from sympy import *\n",
    "L = Matrix(K)\n",
    "H = L.eigenvects()\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b2046e-21c6-49b0-8629-8df162af80ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
